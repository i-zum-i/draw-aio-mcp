#!/usr/bin/env python3
"""
MCP ãƒ—ãƒ­ãƒˆã‚³ãƒ«äº’æ›æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“ç‰ˆï¼‰

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€MCPã‚µãƒ¼ãƒãƒ¼ãŒå…¬å¼MCPä»•æ§˜ã¨äº’æ›æ€§ãŒã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã™ã€‚
"""

import asyncio
import json
import logging
import sys
from datetime import datetime
from typing import Dict, Any, List

# å…¬å¼MCPãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from mcp.types import (
        LATEST_PROTOCOL_VERSION,
        DEFAULT_NEGOTIATED_VERSION,
        InitializeRequestParams,
        Implementation,
        Tool
    )
    MCP_AVAILABLE = True
except ImportError as e:
    print(f"âŒ MCP ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—: {e}")
    MCP_AVAILABLE = False

try:
    from src.config import MCPServerConfig
    from src.server import (
        SERVER_NAME,
        SERVER_VERSION,
        TOOL_DEFINITIONS,
        validate_tool_arguments
    )
    SERVER_AVAILABLE = True
except ImportError as e:
    print(f"âŒ ã‚µãƒ¼ãƒãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—: {e}")
    SERVER_AVAILABLE = False


async def check_protocol_compatibility():
    """ãƒ—ãƒ­ãƒˆã‚³ãƒ«äº’æ›æ€§ã®åŒ…æ‹¬çš„ãƒã‚§ãƒƒã‚¯"""
    print("ğŸ” MCP ãƒ—ãƒ­ãƒˆã‚³ãƒ«äº’æ›æ€§ãƒã‚§ãƒƒã‚¯ã‚’é–‹å§‹...")
    print("=" * 60)
    
    if not MCP_AVAILABLE or not SERVER_AVAILABLE:
        print("âŒ å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        return False
    
    try:
        results = {}
        
        # 1. ãƒ—ãƒ­ãƒˆã‚³ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯
        print("ğŸ“‹ 1. ãƒ—ãƒ­ãƒˆã‚³ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯")
        version_result = check_protocol_version()
        results["protocol_version"] = version_result
        print_result_summary("ãƒ—ãƒ­ãƒˆã‚³ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³", version_result)
        print()
        
        # 2. ã‚µãƒ¼ãƒãƒ¼æ©Ÿèƒ½ãƒã‚§ãƒƒã‚¯
        print("âš™ï¸ 2. ã‚µãƒ¼ãƒãƒ¼æ©Ÿèƒ½ãƒã‚§ãƒƒã‚¯")
        capabilities_result = check_server_capabilities()
        results["server_capabilities"] = capabilities_result
        print_result_summary("ã‚µãƒ¼ãƒãƒ¼æ©Ÿèƒ½", capabilities_result)
        print()
        
        # 3. ãƒ„ãƒ¼ãƒ«å®šç¾©ãƒã‚§ãƒƒã‚¯
        print("ğŸ”§ 3. ãƒ„ãƒ¼ãƒ«å®šç¾©ãƒã‚§ãƒƒã‚¯")
        tools_result = await check_tool_definitions()
        results["tool_definitions"] = tools_result
        print_result_summary("ãƒ„ãƒ¼ãƒ«å®šç¾©", tools_result)
        print()
        
        # 4. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒã‚§ãƒƒã‚¯
        print("ğŸš¨ 4. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒã‚§ãƒƒã‚¯")
        error_result = check_error_handling()
        results["error_handling"] = error_result
        print_result_summary("ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°", error_result)
        print()
        
        # 5. å…¨ä½“è©•ä¾¡
        print("ğŸ“Š 5. å…¨ä½“è©•ä¾¡")
        overall_result = calculate_overall_score(results)
        print_overall_assessment(overall_result)
        
        # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        save_results(results, overall_result)
        
        return overall_result["success"]
        
    except Exception as e:
        print(f"âŒ ãƒã‚§ãƒƒã‚¯ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def check_protocol_version() -> Dict[str, Any]:
    """ãƒ—ãƒ­ãƒˆã‚³ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ãƒã‚§ãƒƒã‚¯"""
    config = MCPServerConfig.from_env()
    server_version = config.protocol_version
    
    official_latest = LATEST_PROTOCOL_VERSION
    official_default = DEFAULT_NEGOTIATED_VERSION
    
    is_latest = server_version == official_latest
    is_supported = server_version in [official_latest, official_default, "2024-11-05"]
    
    # ãƒãƒ¼ã‚¸ãƒ§ãƒ³å½¢å¼ã®æ¤œè¨¼
    version_format_valid = validate_version_format(server_version)
    
    return {
        "server_version": server_version,
        "official_latest": official_latest,
        "official_default": official_default,
        "is_latest": is_latest,
        "is_supported": is_supported,
        "format_valid": version_format_valid,
        "score": 100 if is_latest else (90 if is_supported else 50),
        "success": is_supported and version_format_valid
    }


def validate_version_format(version: str) -> bool:
    """ãƒãƒ¼ã‚¸ãƒ§ãƒ³å½¢å¼ã®æ¤œè¨¼ï¼ˆYYYY-MM-DDï¼‰"""
    try:
        parts = version.split("-")
        if len(parts) != 3:
            return False
        
        year, month, day = parts
        if not (year.isdigit() and month.isdigit() and day.isdigit()):
            return False
        
        year_int = int(year)
        month_int = int(month)
        day_int = int(day)
        
        return (2024 <= year_int <= 2030 and 
                1 <= month_int <= 12 and 
                1 <= day_int <= 31)
    except Exception:
        return False


def check_server_capabilities() -> Dict[str, Any]:
    """ã‚µãƒ¼ãƒãƒ¼æ©Ÿèƒ½ã®ãƒã‚§ãƒƒã‚¯"""
    checks = {
        "server_name_defined": bool(SERVER_NAME),
        "server_version_defined": bool(SERVER_VERSION),
        "tools_defined": len(TOOL_DEFINITIONS) > 0,
        "tool_schemas_valid": validate_tool_schemas()
    }
    
    score = sum(checks.values()) / len(checks) * 100
    success = all(checks.values())
    
    return {
        "checks": checks,
        "score": score,
        "success": success
    }


def validate_tool_schemas() -> bool:
    """ãƒ„ãƒ¼ãƒ«ã‚¹ã‚­ãƒ¼ãƒã®æ¤œè¨¼"""
    try:
        for tool in TOOL_DEFINITIONS:
            if not hasattr(tool, 'name') or not tool.name:
                return False
            if not hasattr(tool, 'description') or not tool.description:
                return False
            if not hasattr(tool, 'inputSchema') or not tool.inputSchema:
                return False
            
            schema = tool.inputSchema
            if not isinstance(schema, dict):
                return False
            if schema.get("type") != "object":
                return False
            if "properties" not in schema:
                return False
        
        return True
    except Exception:
        return False


async def check_tool_definitions() -> Dict[str, Any]:
    """ãƒ„ãƒ¼ãƒ«å®šç¾©ã®ãƒã‚§ãƒƒã‚¯"""
    try:
        # TOOL_DEFINITIONSã‚’ç›´æ¥ä½¿ç”¨ï¼ˆlist_tools()ã¯loggerãŒå¿…è¦ãªãŸã‚ï¼‰
        tools = TOOL_DEFINITIONS
        
        checks = {
            "tools_returned": len(tools) > 0,
            "expected_tool_count": len(tools) >= 3,
            "all_tools_valid": all(
                hasattr(tool, 'name') and hasattr(tool, 'description') and hasattr(tool, 'inputSchema')
                for tool in tools
            )
        }
        
        # å„ãƒ„ãƒ¼ãƒ«ã®è©³ç´°ãƒã‚§ãƒƒã‚¯
        tool_details = []
        for tool in tools:
            detail = {
                "name": tool.name,
                "has_description": bool(tool.description),
                "has_schema": bool(tool.inputSchema),
                "schema_valid": validate_single_tool_schema(tool.inputSchema) if tool.inputSchema else False
            }
            tool_details.append(detail)
        
        score = sum(checks.values()) / len(checks) * 100
        success = all(checks.values())
        
        return {
            "checks": checks,
            "tool_details": tool_details,
            "tool_count": len(tools),
            "score": score,
            "success": success
        }
        
    except Exception as e:
        return {
            "checks": {"error": True},
            "error": str(e),
            "score": 0,
            "success": False
        }


def validate_single_tool_schema(schema: Dict[str, Any]) -> bool:
    """å˜ä¸€ãƒ„ãƒ¼ãƒ«ã‚¹ã‚­ãƒ¼ãƒã®æ¤œè¨¼"""
    try:
        if not isinstance(schema, dict):
            return False
        if schema.get("type") != "object":
            return False
        if "properties" not in schema:
            return False
        return True
    except Exception:
        return False


def check_error_handling() -> Dict[str, Any]:
    """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ãƒã‚§ãƒƒã‚¯"""
    error_tests = []
    
    # ç„¡åŠ¹ãªå¼•æ•°ã§ã®ãƒ†ã‚¹ãƒˆ
    test_cases = [
        {
            "tool": "generate-drawio-xml",
            "args": {},  # å¿…é ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãªã—
            "expected_error": "å¿…é ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ 'prompt' ãŒä¸è¶³ã—ã¦ã„ã¾ã™"
        },
        {
            "tool": "save-drawio-file",
            "args": {},  # å¿…é ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãªã—
            "expected_error": "å¿…é ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ 'xml_content' ãŒä¸è¶³ã—ã¦ã„ã¾ã™"
        },
        {
            "tool": "convert-to-png",
            "args": {},  # å¿…é ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãªã—
            "expected_error": "'file_id' ã¾ãŸã¯ 'file_path' ã®ã„ãšã‚Œã‹ãŒå¿…è¦ã§ã™"
        }
    ]
    
    for test_case in test_cases:
        try:
            validate_tool_arguments(test_case["tool"], test_case["args"])
            error_tests.append({
                "tool": test_case["tool"],
                "error_caught": False,
                "expected": test_case["expected_error"],
                "actual": None
            })
        except ValueError as e:
            error_message = str(e)
            error_tests.append({
                "tool": test_case["tool"],
                "error_caught": True,
                "expected": test_case["expected_error"],
                "actual": error_message,
                "message_correct": test_case["expected_error"] in error_message
            })
        except Exception as e:
            error_tests.append({
                "tool": test_case["tool"],
                "error_caught": True,
                "expected": test_case["expected_error"],
                "actual": str(e),
                "message_correct": False
            })
    
    all_errors_caught = all(test["error_caught"] for test in error_tests)
    correct_messages = all(
        test.get("message_correct", False) for test in error_tests if test["error_caught"]
    )
    
    score = (sum(test["error_caught"] for test in error_tests) / len(error_tests)) * 100
    success = all_errors_caught and correct_messages
    
    return {
        "error_tests": error_tests,
        "all_errors_caught": all_errors_caught,
        "correct_messages": correct_messages,
        "score": score,
        "success": success
    }


def calculate_overall_score(results: Dict[str, Any]) -> Dict[str, Any]:
    """å…¨ä½“ã‚¹ã‚³ã‚¢ã®è¨ˆç®—"""
    weights = {
        "protocol_version": 0.3,
        "server_capabilities": 0.25,
        "tool_definitions": 0.25,
        "error_handling": 0.2
    }
    
    total_score = 0
    for category, weight in weights.items():
        if category in results and "score" in results[category]:
            total_score += results[category]["score"] * weight
    
    # æˆåŠŸåˆ¤å®š
    all_success = all(
        results[category].get("success", False) 
        for category in weights.keys() 
        if category in results
    )
    
    # ãƒ¬ãƒ™ãƒ«åˆ¤å®š
    if total_score >= 95:
        level = "EXCELLENT"
        message = "âœ… å®Œå…¨ã«MCPä»•æ§˜ã«æº–æ‹ ã—ã¦ã„ã¾ã™"
    elif total_score >= 85:
        level = "GOOD"
        message = "âœ… MCPä»•æ§˜ã«ååˆ†æº–æ‹ ã—ã¦ã„ã¾ã™"
    elif total_score >= 70:
        level = "ACCEPTABLE"
        message = "âš ï¸ MCPä»•æ§˜ã«æ¦‚ã­æº–æ‹ ã—ã¦ã„ã¾ã™ãŒã€æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚Šã¾ã™"
    else:
        level = "NEEDS_IMPROVEMENT"
        message = "âŒ MCPä»•æ§˜ã¸ã®æº–æ‹ ã«å•é¡ŒãŒã‚ã‚Šã¾ã™"
    
    return {
        "total_score": round(total_score, 2),
        "level": level,
        "message": message,
        "success": all_success and total_score >= 85,
        "category_scores": {
            category: results[category].get("score", 0) 
            for category in weights.keys() 
            if category in results
        }
    }


def print_result_summary(category: str, result: Dict[str, Any]):
    """çµæœã‚µãƒãƒªãƒ¼ã®è¡¨ç¤º"""
    success = result.get("success", False)
    score = result.get("score", 0)
    
    status = "âœ… åˆæ ¼" if success else "âŒ ä¸åˆæ ¼"
    print(f"   çµæœ: {status} (ã‚¹ã‚³ã‚¢: {score:.1f}/100)")
    
    if "checks" in result:
        for check_name, check_result in result["checks"].items():
            check_status = "âœ…" if check_result else "âŒ"
            print(f"   {check_name}: {check_status}")


def print_overall_assessment(overall: Dict[str, Any]):
    """å…¨ä½“è©•ä¾¡ã®è¡¨ç¤º"""
    print(f"   ç·åˆã‚¹ã‚³ã‚¢: {overall['total_score']}/100")
    print(f"   è©•ä¾¡ãƒ¬ãƒ™ãƒ«: {overall['level']}")
    print(f"   ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {overall['message']}")
    print()
    
    print("   ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚¹ã‚³ã‚¢:")
    for category, score in overall["category_scores"].items():
        print(f"     {category}: {score:.1f}")


def save_results(results: Dict[str, Any], overall: Dict[str, Any]):
    """çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    report = {
        "timestamp": datetime.now().isoformat(),
        "server_info": {
            "name": SERVER_NAME,
            "version": SERVER_VERSION
        },
        "test_results": results,
        "overall_assessment": overall
    }
    
    filename = f"mcp_compatibility_check_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜: {filename}")


async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    # ãƒ­ã‚°è¨­å®š
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    # äº’æ›æ€§ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
    success = await check_protocol_compatibility()
    
    if success:
        print("\nğŸ‰ MCP ãƒ—ãƒ­ãƒˆã‚³ãƒ«äº’æ›æ€§ãƒã‚§ãƒƒã‚¯å®Œäº† - ã™ã¹ã¦æ­£å¸¸")
        return 0
    else:
        print("\nâŒ MCP ãƒ—ãƒ­ãƒˆã‚³ãƒ«äº’æ›æ€§ãƒã‚§ãƒƒã‚¯å®Œäº† - å•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)